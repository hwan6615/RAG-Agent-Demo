# main.py

import json
import numpy as np
import pandas as pd
from openai import OpenAI
from sklearn.metrics.pairwise import cosine_similarity
from rank_bm25 import BM25Okapi
import ast
from datasets import load_dataset
from dotenv import load_dotenv
from tavily import TavilyClient
import os

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# 1. ë°ì´í„° ë¡œë“œ (Salesforce xLAM ë°ì´í„°ì…‹ ì—°ë™)
# ---------------------------------------------------------
# main.py

def load_data():
    tools = []
    
    # ---------------------------------------------------------
    # 1. ê¸°ë³¸ ë°ì´í„° ë¡œë“œ (JSON íŒŒì¼ ë˜ëŠ” HuggingFace)
    # ---------------------------------------------------------
    try:
        # ë¨¼ì € ë¡œì»¬ì— ìƒ˜í”Œë§í•´ë‘” íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
        with open("selected_tools.json", "r", encoding="utf-8") as f:
            tools = json.load(f)
            print(f"ğŸ“‚ ë¡œì»¬ ë°ì´í„°ì…‹(selected_tools.json) ë¡œë“œ ì™„ë£Œ: {len(tools)}ê°œ")
    except FileNotFoundError:
        print("âš ï¸ ë¡œì»¬ íŒŒì¼ì´ ì—†ì–´ HuggingFaceì—ì„œ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤ (100ê°œ ì œí•œ).")
        try:
            # ë¡œì»¬ íŒŒì¼ ì—†ìœ¼ë©´ HuggingFaceì—ì„œ ì‹¤ì‹œê°„ ë¡œë“œ (ê¸°ì¡´ ë¡œì§)
            dataset = load_dataset("Salesforce/xlam-function-calling-60k", split="train", streaming=True)
            for i, item in enumerate(dataset):
                if i >= 100: break
                if 'tools' in item:
                    try:
                        tool_list = item['tools'] if isinstance(item['tools'], list) else json.loads(item['tools'])
                        tools.extend(tool_list)
                    except:
                        continue
        except Exception as e:
            print(f"âš ï¸ ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨: {e}")

    # ---------------------------------------------------------
    # 2. [í•µì‹¬] ì»¤ìŠ¤í…€ ë„êµ¬(Tavily ë“±) ê°•ì œ ì£¼ì… (Injection)
    # ---------------------------------------------------------
    # ì´ ë¶€ë¶„ì´ ë¹ ì ¸ ìˆì–´ì„œ ê²€ìƒ‰ì´ ì•ˆ ë˜ì—ˆë˜ ê²ƒì…ë‹ˆë‹¤!
    custom_tools = [
        {
            "name": "search_web",
            "description": (
                "A powerful internet search engine. "
                "Use this for 'latest news', 'current events', 'AI trends'. "
                "í•œêµ­ì–´ ì§ˆë¬¸: 'ì›¹ ê²€ìƒ‰', 'ìµœì‹  ë‰´ìŠ¤', 'íŠ¸ë Œë“œ', 'ì •ë³´ ê²€ìƒ‰'ì´ í•„ìš”í•  ë•Œ ë°˜ë“œì‹œ ì´ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."  # <--- í•œêµ­ì–´ í‚¤ì›Œë“œ ì¶”ê°€!
            ),
            "parameters": {
                "type": "object", 
                "properties": {"query": {"type": "string", "description": "The search query."}},
                "required": ["query"]
            }
        },
        {
            "name": "get_weather",
            "description": "Get the current weather for a specific location.",
            "parameters": {
                "type": "object", 
                "properties": {"city": {"type": "string", "description": "The city and state, e.g. San Francisco, CA"}},
                "required": ["city"]
            }
        },
        {
            "name": "get_stock_price",
            "description": "Get the current stock price for a given ticker symbol.",
            "parameters": {
                "type": "object", 
                "properties": {"ticker": {"type": "string", "description": "The stock ticker symbol, e.g. AAPL"}},
                "required": ["ticker"]
            }
        }
    ]

    print(f"ğŸ’‰ ì»¤ìŠ¤í…€ ë„êµ¬ {len(custom_tools)}ê°œë¥¼ ë„êµ¬ í’€ì— ì£¼ì…í•©ë‹ˆë‹¤.")
    tools.extend(custom_tools)
    
    # ì¤‘ë³µ ì œê±° (í˜¹ì‹œ ëª¨ë¥¼ ì¤‘ë³µ ë°©ì§€)
    unique_tools = {t['name']: t for t in tools if 'name' in t}
    final_tools = list(unique_tools.values())
    
    print(f"âœ… ìµœì¢… ë„êµ¬ í’€ í¬ê¸°: {len(final_tools)}ê°œ")
    
    # [ê²€ì¦] search_webì´ ì§„ì§œ ë“¤ì–´ê°”ëŠ”ì§€ í™•ì¸
    if any(t['name'] == 'search_web' for t in final_tools):
        print("ğŸ” í™•ì¸: 'search_web' ë„êµ¬ê°€ ì„±ê³µì ìœ¼ë¡œ í¬í•¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("ğŸš¨ ê²½ê³ : 'search_web' ë„êµ¬ê°€ í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")

    return final_tools

# ---------------------------------------------------------
# 2. Hybrid Retriever & Reranking (ê²€ìƒ‰ ê³ ë„í™”)
# ---------------------------------------------------------
class HybridRetriever:
    def __init__(self, tools, embeddings, client):
        self.tools = tools
        self.embeddings = embeddings  # ë¯¸ë¦¬ ì„ë² ë”©ëœ ë„êµ¬ ì„¤ëª… ë²¡í„°ë“¤
        self.client = client
        
        # BM25 ì¸ë±ì‹± (í‚¤ì›Œë“œ ê²€ìƒ‰ìš©)
        tokenized_corpus = [tool['description'].lower().split() for tool in tools]
        self.bm25 = BM25Okapi(tokenized_corpus)

    def search(self, query, query_embedding, top_k=20):
        """
        BM25(í‚¤ì›Œë“œ)ì™€ Vector(ì˜ë¯¸) ê²€ìƒ‰ì„ ê²°í•©í•œ Hybrid Search
        """
        # 1. Vector Search
        similarities = cosine_similarity([query_embedding], self.embeddings)[0]
        # ì ìˆ˜ ì •ê·œí™” (0~1)
        # (ê°„ë‹¨í•œ ì˜ˆì‹œ: min-max normalization ë¡œì§ ì¶”ê°€ ê°€ëŠ¥)
        
        # 2. Keyword Search (BM25)
        tokenized_query = query.lower().split()
        bm25_scores = self.bm25.get_scores(tokenized_query)
        # ì ìˆ˜ ì •ê·œí™” í•„ìš” (BM25ëŠ” ì ìˆ˜ ë²”ìœ„ê°€ í¼, ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœ í•©ì‚° ì˜ˆì‹œ)
        bm25_scores = (bm25_scores - np.min(bm25_scores)) / (np.max(bm25_scores) - np.min(bm25_scores) + 1e-9)

        # 3. Hybrid Score (ê°€ì¤‘ì¹˜ ì¡°ì ˆ ê°€ëŠ¥: Vector 0.7 + BM25 0.3)
        hybrid_scores = 0.7 * similarities + 0.3 * bm25_scores
        
        # Top-K ì¶”ì¶œ
        top_indices = np.argsort(hybrid_scores)[::-1][:top_k]
        candidates = [self.tools[i] for i in top_indices]
        
        return self.rerank(query, candidates)

    def rerank(self, query, candidates):
        """
        GPT-4o-minië¥¼ ë¦¬ë­ì»¤(Reranker)ë¡œ ì‚¬ìš©í•˜ì—¬ í›„ë³´êµ° ì••ì¶•
        """
        candidate_str = "\n".join([f"{i}. {t['name']}: {t['description']}" for i, t in enumerate(candidates)])
        
        prompt = f"""
        User Query: "{query}"
        
        Below is a list of potential tools. Select the top 3 tools that are most relevant to solving the user's query.
        Return ONLY the indices of the tools (e.g., [0, 2, 5]).
        
        Tools:
        {candidate_str}
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0
            )
            indices = json.loads(response.choices[0].message.content)
            final_tools = [candidates[i] for i in indices if i < len(candidates)]
            return final_tools if final_tools else candidates[:5]
        except:
            return candidates[:3] # ì—ëŸ¬ ì‹œ ìƒìœ„ 3ê°œ ë°˜í™˜

# ---------------------------------------------------------
# 3. Agent Class (Planning + Self-Correction)
# ---------------------------------------------------------
class Agent:
    def __init__(self, client, retriever):
        self.client = client
        self.retriever = retriever
        self.max_retries = 2
        self.history = [] # ëŒ€í™” ë° ìƒê°ì˜ íë¦„ ì €ì¥

    def get_embedding(self, text):
        response = self.client.embeddings.create(
            input=text, model="text-embedding-3-small"
        )
        return response.data[0].embedding

    # [ìˆ˜ì • 3] ì•ˆì „í•œ JSON íŒŒì‹± í—¬í¼ í•¨ìˆ˜
    def parse_json_safely(self, text):
        try:
            # 1. ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±° (```json ... ```)
            cleaned_text = text.strip()
            if "```" in cleaned_text:
                cleaned_text = cleaned_text.split("```")[1]
                if cleaned_text.startswith("json"):
                    cleaned_text = cleaned_text[4:]
            
            # 2. JSON íŒŒì‹±
            return json.loads(cleaned_text.strip())
        except:
            # JSONì´ ì•„ë‹ˆë©´ (ì¼ë°˜ í…ìŠ¤íŠ¸ ë‹µë³€ì´ë©´) None ë°˜í™˜
            return None
        
    def run(self, user_query, status_container=None): # status_container ì¶”ê°€
        self.history = [{"role": "user", "content": user_query}]
        logs = [] 

        # 1. ì´ˆê¸° ë„êµ¬ ê²€ìƒ‰
        query_embedding = self.get_embedding(user_query)
        relevant_tools = self.retriever.search(user_query, query_embedding)
        logs.append({"step": "Retrieval", "content": relevant_tools})
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê°•í™”: ë„êµ¬ ì‚¬ìš© ì‹œì™€ ìµœì¢… ë‹µë³€ ì‹œë¥¼ ëª…í™•íˆ êµ¬ë¶„
        system_prompt = f"""
        You are an intelligent agent.
        You have access to the following tools:
        {json.dumps(relevant_tools, indent=2)}

        [INSTRUCTIONS]
        1. To use a tool, you MUST output a JSON block like this:
        ```json
        {{
            "tool_name": "tool_name_here",
            "arguments": {{ "arg_name": "value" }}
        }}
        ```
        2. If you have the final answer or if no tool is relevant, just write the answer in plain text.
        3. Do NOT include any explanations outside the JSON when calling a tool.
        """
        
        # historyì˜ ì²« ë²ˆì§¸ì— ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ê°€ ì˜¤ë„ë¡ ì„¤ì • (ë§¤ë²ˆ ê°±ì‹ )
        messages = [{"role": "system", "content": system_prompt}] + self.history

        # 2. Planning & Execution Loop
        max_steps = 5
        for step in range(max_steps):
            
            # UIì— ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸ (ì‚¬ìš©ìê°€ ë©ˆì·„ë‹¤ê³  ëŠë¼ì§€ ì•Šê²Œ)
            if status_container:
                status_container.markdown(f"ğŸ”„ **Step {step+1}/{max_steps}**: ìƒê°í•˜ê³  ì¶”ë¡ í•˜ëŠ” ì¤‘...")

            # [ìˆ˜ì • 1] response_format ì œê±° -> í…ìŠ¤íŠ¸ì™€ JSON ììœ ë¡­ê²Œ ì‚¬ìš©
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                temperature=0 
            )
            content = response.choices[0].message.content
            
            # [ìˆ˜ì • 2] ë§ˆí¬ë‹¤ìš´ ë°±í‹± ì œê±° ë° JSON íŒŒì‹± ì‹œë„
            action = self.parse_json_safely(content)

            # A. ë„êµ¬ í˜¸ì¶œì¸ ê²½ìš° (JSON íŒŒì‹± ì„±ê³µ ë° tool_name ì¡´ì¬)
            if action and "tool_name" in action:
                tool_name = action["tool_name"]
                args = action.get("arguments", {})
                
                logs.append({"step": "Plan", "content": f"Decided to call {tool_name} with {args}"})
                
                # Mock Execution
                result, is_error = self.mock_execute(tool_name, args)
                
                logs.append({"step": "Execution", "content": f"Result: {result}"})
                
                # ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€ (LLMì´ ê²°ê³¼ë¥¼ ì•Œì•„ì•¼ í•¨)
                self.history.append({"role": "assistant", "content": content})
                self.history.append({"role": "user", "content": f"Tool output: {result}"})
                messages = [{"role": "system", "content": system_prompt}] + self.history

            # B. ìµœì¢… ë‹µë³€ì¸ ê²½ìš° (JSONì´ ì•„ë‹ˆê±°ë‚˜ tool_nameì´ ì—†ìŒ)
            else:
                logs.append({"step": "Final Answer", "content": content})
                self.history.append({"role": "assistant", "content": content})
                return content, logs
                
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ë„ˆë¬´ ë§ì€ ë‹¨ê³„ê°€ ì†Œìš”ë˜ì–´ ë‹µë³€ì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.", logs

    # Agent í´ë˜ìŠ¤ ë‚´ë¶€
    def mock_execute(self, tool_name, args):
        """
        [Hybrid Execution]
        1. ê²€ìƒ‰ ë„êµ¬ -> Tavily API ì‹¤ì‹œê°„ í˜¸ì¶œ (Real)
        2. ë‚ ì”¨/ì£¼ì‹ -> ë°ëª¨ìš© ê°€ì§œ ë°ì´í„° (Mock)
        3. ê·¸ ì™¸ -> ì‹¤í–‰ ì„±ê³µ ë¡œê·¸ë§Œ ë°˜í™˜ (Simulation)
        """
        
        # ---------------------------------------------------------
        # Case 1: [Real] ì›¹ ê²€ìƒ‰ (Tavily ì—°ë™)
        # ---------------------------------------------------------
        # xLAMì´ 'search_web', 'google_search', 'bing_search' ë“± ë­˜ ê°€ì ¸ì˜¤ë“ 
        # ì´ë¦„ì— 'search', 'web', 'news'ê°€ ìˆìœ¼ë©´ Tavilyë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        if any(k in tool_name.lower() for k in ["search", "web", "news"]):
            try:
                # 1. API í‚¤ ë¡œë“œ
                tavily_key = os.getenv("TAVILY_API_KEY")
                if not tavily_key:
                    return "Error: TAVILY_API_KEY not found in .env", True

                # 2. í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
                tavily = TavilyClient(api_key=tavily_key)
                
                # 3. ê²€ìƒ‰ ì¿¼ë¦¬ ì¶”ì¶œ (xLAM ë„êµ¬ë§ˆë‹¤ íŒŒë¼ë¯¸í„° ì´ë¦„ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
                query = args.get("query") or args.get("q") or args.get("search_term")
                if not query:
                    return "Error: No query provided in arguments", True

                # 4. ì‹¤ì œ ê²€ìƒ‰ ì‹¤í–‰ (ìš”ì•½ë³¸ë§Œ ê°€ì ¸ì˜¤ê¸°)
                print(f"ğŸŒ Tavily ê²€ìƒ‰ ì‹¤í–‰: {query}")
                search_result = tavily.search(query=query, search_depth="basic", max_results=3)
                
                # 5. ê²°ê³¼ ë°˜í™˜ (LLMì´ ì½ì„ ìˆ˜ ìˆê²Œ JSON ë¬¸ìì—´ë¡œ ë³€í™˜)
                # context ë¦¬ìŠ¤íŠ¸ë§Œ ë½‘ì•„ì„œ ì¤ë‹ˆë‹¤.
                results = search_result.get("results", [])
                return json.dumps(results, ensure_ascii=False), False

            except Exception as e:
                return f"Error during Tavily search: {str(e)}", True

        # ---------------------------------------------------------
        # Case 2: [Mock] ë‚ ì”¨ (ë°ëª¨ìš©)
        # ---------------------------------------------------------
        elif "weather" in tool_name.lower():
            city = args.get("city", "Unknown City")
            return json.dumps({
                "city": city,
                "temperature": "22Â°C", 
                "condition": "Partly Cloudy", 
                "humidity": "45%",
                "note": "This is mock data."
            }), False
            
        # ---------------------------------------------------------
        # Case 3: [Mock] ì£¼ì‹ (ë°ëª¨ìš©)
        # ---------------------------------------------------------
        elif "stock" in tool_name.lower():
            ticker = args.get("ticker", "UNKNOWN")
            return json.dumps({
                "ticker": ticker,
                "price": "$150.25", 
                "change": "+1.25%",
                "status": "Market Open",
                "note": "This is mock data."
            }), False

        # ---------------------------------------------------------
        # Case 4: [Generic] ê·¸ ì™¸ ëª¨ë“  ë„êµ¬
        # ---------------------------------------------------------
        else:
            return f"âœ… [Simulation] Tool '{tool_name}' executed successfully. (No real action performed)", False

# ---------------------------------------------------------
# ì´ˆê¸°í™” í—¬í¼ í•¨ìˆ˜
# ---------------------------------------------------------
def initialize_system(api_key, tools_data, tool_embeddings):
    client = OpenAI(api_key=api_key)
    retriever = HybridRetriever(tools_data, tool_embeddings, client)
    agent = Agent(client, retriever)
    return agent