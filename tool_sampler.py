# tools_sampler.py
import json
import random
from datasets import load_dataset
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

def create_sampled_dataset():
    print("ğŸ“¥ xLAM ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ìŠ¤íŠ¸ë¦¬ë° ì¤‘...")
    dataset = load_dataset("Salesforce/xlam-function-calling-60k", split="train", streaming=True)
    
    # 1. ìš°ë¦¬ê°€ ì›í•˜ëŠ” í•µì‹¬ ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ
    target_keywords = ["weather", "math", "stock", "finance", "news", "search", "email", "calendar"]
    
    selected_tools = []
    seen_names = set()
    
    print("ğŸ” ë„êµ¬ í•„í„°ë§ ì¤‘...")
    
    # ì „ì²´ ë°ì´í„°ë¥¼ ìˆœíšŒí•˜ë©° ì„ ë³„ (ìµœëŒ€ 10,000ê°œë§Œ í™•ì¸)
    for i, item in enumerate(dataset):
        if i > 10000: break 
        
        try:
            # ë„êµ¬ íŒŒì‹±
            tools = item['tools'] if isinstance(item['tools'], list) else json.loads(item['tools'])
            
            for tool in tools:
                name = tool['name'].lower()
                desc = tool['description'].lower()
                
                # ì¤‘ë³µ ì œê±°
                if name in seen_names: continue
                
                # ì „ëµ 1: í•µì‹¬ ì¹´í…Œê³ ë¦¬ëŠ” ë¬´ì¡°ê±´ í¬í•¨
                is_target = any(k in name or k in desc for k in target_keywords)
                
                # ì „ëµ 2: í•µì‹¬ì´ ì•„ë‹ˆë”ë¼ë„ ëœë¤í•˜ê²Œ 5% í™•ë¥ ë¡œ í¬í•¨ (RAG ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ìš© ë…¸ì´ì¦ˆ)
                is_random = random.random() < 0.05
                
                if is_target or is_random:
                    selected_tools.append(tool)
                    seen_names.add(name)
                    
        except Exception as e:
            continue

    print(f"âœ… ì´ {len(selected_tools)}ê°œì˜ ë„êµ¬ê°€ ì„ ë³„ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # íŒŒì¼ë¡œ ì €ì¥ (main.pyì—ì„œ ì´ê±¸ ë¡œë“œí•´ì„œ ì“°ë©´ ë¨)
    with open("selected_tools.json", "w", encoding="utf-8") as f:
        json.dump(selected_tools, f, indent=2, ensure_ascii=False)
    
    print("ğŸ’¾ 'selected_tools.json' ì €ì¥ ì™„ë£Œ!")

if __name__ == "__main__":
    create_sampled_dataset()